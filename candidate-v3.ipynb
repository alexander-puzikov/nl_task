{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестовое задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общие требования:**\n",
    "1. приложить файл requirements.txt с пакетами, которые необходимо установить для воспроизведения результата.\n",
    "1. комментировать ход решения.\n",
    "1. **дополнительное задание на подумать:** есть ли метрики, которые лучше подходят для задачи?\n",
    "1. **дополнительное задание на подумать:** как изменилось бы решение, если бы модель необходимо было встроить в другую систему, используя Java?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.cluster.hierarchy as hierarchy\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve,roc_auc_score,silhouette_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.plotting import scatter_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ./task1_train_v3.csv does not exist: './task1_train_v3.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e918a0740ea8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## 1. Классификация\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtask1data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./task1_train_v3.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m';'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtask1data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File ./task1_train_v3.csv does not exist: './task1_train_v3.csv'"
     ]
    }
   ],
   "source": [
    "## 1. Классификация\n",
    "task1data = pd.read_csv('./task1_train_v3.csv', sep=';',header=0,index_col=False)\n",
    "task1data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача:** для заданного набора данных (task1_train.csv) построить классификатор. Метрика: AUC ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "task1data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В характеристике stat_2 есть пробелы (nan), лучше посмотреть как обстоят дела со всеми характеристиками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "task1data.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В среднем, у всех статистик есть такие пробелы, они небольшие и какая-то отдельная характеристика не выделяется, а значит, мы просто отфильтруем эти \"плохие\" наблюдения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "task1data.groupby(['y']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отклик **y** распределён неплохо, ни один из 2х классов не доминирует. \n",
    "\n",
    "Поскольку характеристик всего 8, можно спокойно посмотреть на их гистограммы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "task1data['stat_1'].hist(bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "task1data['stat_2'].hist(bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "task1data['stat_3'].hist(bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "task1data['stat_4'].hist(bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "task1data['stat_5'].hist(bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "task1data['stat_6'].hist(bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "task1data['stat_7'].hist(bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "task1data['stat_8'].hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судя по гистограммам, есть явные выбросы, которые стоит убрать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "valid_task1data = task1data.drop(task1data[(task1data['stat_1']) > 350].index)\n",
    "valid_task1data = valid_task1data.drop(valid_task1data[(valid_task1data['stat_3']  > 40)].index)\n",
    "valid_task1data = valid_task1data.drop(valid_task1data[(valid_task1data['stat_4']  > 80)].index)\n",
    "valid_task1data = valid_task1data.drop(valid_task1data[(valid_task1data['stat_5']  > 50)].index)\n",
    "valid_task1data = valid_task1data.drop(valid_task1data[(valid_task1data['stat_6']  > 70)].index)\n",
    "valid_task1data = valid_task1data.drop(valid_task1data[(valid_task1data['stat_7']  > 50)].index)\n",
    "valid_task1data = valid_task1data.drop(valid_task1data[(valid_task1data['stat_8']  > 50)].index)\n",
    "valid_task1data = valid_task1data.dropna()\n",
    "valid_task1data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "valid_task1data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "colors={'1':'green', '0':'red'}\n",
    "valid_task1data['y'] = valid_task1data['y'].astype(str)\n",
    "scatter_matrix(valid_task1data,figsize=(26,26), diagonal='kde',alpha=0.2, c=valid_task1data['y'].replace(colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Диаграммы рассеивания могли нам указать на явно значимиые характеристики, но не в этом случае. После того, как убрали выбросы ещё раз взглянем на гистограмму, к примеру, первой характеристики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "valid_task1data['stat_1'].hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если внимательно взглянуть на диаграммы рассеивания, то можно заметить что stat_5 и stat_6 практически линейно друг от друга зависят, проверить это можем с помощью корреляции Пирсона."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "valid_task1data['stat_5'].corr(valid_task1data['stat_6']),valid_task1data['stat_6'].corr(valid_task1data['stat_5'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что и требовалось доказать. Уберём, допустим, 5ю характеристику, она избыточна.\n",
    "\n",
    "\n",
    "7 и 8 характеристики тоже смущают.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "valid_task1data['stat_7'].corr(valid_task1data['stat_8']),valid_task1data['stat_8'].corr(valid_task1data['stat_7'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7ю характеристику в сад, но смущают 8я и 4я...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "valid_task1data['stat_8'].corr(valid_task1data['stat_4']),valid_task1data['stat_4'].corr(valid_task1data['stat_8'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4ю тоже в сад."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%m\n"
    }
   },
   "outputs": [],
   "source": [
    "filtered_valid_task1data=valid_task1data.drop('stat_5',axis=1)\n",
    "filtered_valid_task1data=filtered_valid_task1data.drop('stat_4',axis=1)\n",
    "filtered_valid_task1data=filtered_valid_task1data.drop('stat_7',axis=1)\n",
    "x = filtered_valid_task1data.drop('y',axis=1)\n",
    "y = filtered_valid_task1data['y']\n",
    "colors={'1':'green', '0':'red'}\n",
    "filtered_valid_task1data['y'] = filtered_valid_task1data['y'].astype(str)\n",
    "scatter_matrix(filtered_valid_task1data,figsize=(26,26), diagonal='kde',alpha=0.2, c=filtered_valid_task1data['y'].replace(colors))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_x,test_and_validate_x,train_y,test_and_validate_y= train_test_split(x, y, stratify=y,  test_size=0.4, random_state=42)\n",
    "{'train': train_y, 'test_and_ validate': test_and_validate_y}\n",
    "train_y.groupby(train_y).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распилить по индексу 3000 оказалось вполне пригодным решением, **y** сохранил репрезентативность и в подвыборках.\n",
    "Но мы воспользуемся **train_test_split**. Судя по тому,что значения отклик **y** принимает только 0 и 1, мы можем рассматривать эту шкалу как номинативную (бинарный индикатор), а значит можно попробовать использовать регрессию или случайный лес, а лучше GBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "validate_x,test_x,validate_y,test_y= train_test_split(test_and_validate_x, test_and_validate_y, stratify=test_and_validate_y,  test_size=0.5, random_state=42)\n",
    "{'train': train_y, 'test': test_y}\n",
    "validate_y.groupby(validate_y).count(),test_y.groupby(test_y).count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выборка валидации использована для подгонки стандартных внешних параметров модели. Сделаем что-то наподобии gridsearch только своими руками через циклы! В качестве промежуточной оценки для валидации возьму **accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_score = -100000\n",
    "for criterion in ('friedman_mse','mae','mse'):\n",
    "    for n_estimators in (100,110,120,130):\n",
    "        for max_depth in range(1,5):\n",
    "            model = GradientBoostingClassifier(random_state=52,\n",
    "                                               max_depth=max_depth, # глубина каждого дерева (значение по умолчанию)\n",
    "                                               n_estimators=n_estimators, # количество деревьев (значение по умолчанию)\n",
    "                                               criterion=criterion # функция измерения качества разбиения\n",
    "                                              )\n",
    "            model.fit(train_x, train_y)\n",
    "            pred_validate_y = model.predict(validate_x)\n",
    "            score = accuracy_score(pred_validate_y , validate_y)            \n",
    "            max_score = max(score, max_score)\n",
    "            print('criterion - ' + criterion + ' n_estimators - '+ str(n_estimators)+' maxdepth - '+str(max_depth)+' : '+ str(score))\n",
    "max_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что максимальная точность достигается при параметрах 120, 4, friedman_mse. Глубину больше 4х не будем рассматривать, так как есть эвристики, что слишком глубокие деревья любят переобучаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier(random_state=52,\n",
    "                                               max_depth=4, # глубина каждого дерева (значение по умолчанию)\n",
    "                                               n_estimators=120, # количество деревьев (значение по умолчанию)\n",
    "                                               criterion='friedman_mse' # функция измерения качества разбиения\n",
    "                                              )\n",
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pred_test_y = model.predict_proba(test_x)\n",
    "print(pred_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "fpr, tpr, thresholds = roc_curve(test_y.astype('int'), pred_test_y[:,1], pos_label=1)\n",
    "lw = 1\n",
    "plt.plot(fpr, tpr, lw=lw, label='ROC curve ')\n",
    "plt.plot([0, 1],[0, 1])\n",
    "plt.xlim([0.0, 1.])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.savefig(\"ROC.png\")\n",
    "plt.show()\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Порог стоит выбрать таким, чтобы tpr - fpr был максимальным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_index = np.argmax(tpr-fpr)\n",
    "roc_score = roc_auc_score(test_y.astype('int'), pred_test_y[:,1])\n",
    "print('порог - '+ str(thresholds[max_index])) \n",
    "print('true positive rate(recall) - '+ str(tpr[max_index]))# \n",
    "print('false positive rate - '+ str(fpr[max_index]))\n",
    "print('roc score - ' +str(roc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> как изменилось бы решение, если бы модель необходимо было встроить в другую систему, используя Java?\n",
    "\n",
    "Первое, что приходит на ум, это организовать отдельный сервис **А** с уже предобученной моделью и производящей результат предсказания.\n",
    "1. Flask в качестве библиотеки http для оргазинации сервера и любая, к примеру httpclientlite, библиотека на стороне Java для организации клиента. (если нужен real-time)\n",
    "2. Организовать 2 очереди с помощью любого подходящего хранилища (mysql или тот же zookeeper), в первой будут запросы на предсказание, во второй результаты.\n",
    "3. Возможно, стоит подумать об отказе от Python в пользу Hadoop кластера и SparkML на его основе (кстати опыт в этих вещах у меня есть :-) ).\n",
    "\n",
    "В любом случае, дообучение и обновление можно организовать в виде jenkins/teamcity или другого варианта cron-таски, а саму модель хранить в виде ресурса, к примеру sklearn.externals.joblib дампа, который будет читаться сервисом **А** на старте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> есть ли метрики, которые лучше подходят для задачи?\n",
    "\n",
    "Основным критерием отказа от **accuracy** обычно считается несбалансированность в классах, \n",
    "у нас же объектов одного и другого типа примерно одинаковое количество, \n",
    "поэтому отказываться от accuracy не имеет смысла."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точно так же и precision/recall/f-score не стоит списывать со счетов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compare_to_threshold(x):\n",
    "    return x > thresholds[max_index]\n",
    "y_pred_test_no_prob = compare_to_threshold(pred_test_y[:,1])\n",
    "y_pred_test_no_prob = y_pred_test_no_prob.astype(int)\n",
    "y_pred_test_no_prob = y_pred_test_no_prob.astype(str).astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_score(test_y, y_pred_test_no_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(classification_report(test_y, y_pred_test_no_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача выглядит так, что её можно проверить с помощью логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(random_state=42,solver='liblinear', multi_class='ovr', penalty='l2')\n",
    "# help(LogisticRegression)\n",
    "model.fit(train_x, train_y)\n",
    "linear_pred_test_y=model.predict_proba(test_x)\n",
    "plt.figure(figsize=(10, 8))\n",
    "fpr, tpr, thresholds = roc_curve(test_y.astype('int'), linear_pred_test_y[:,1], pos_label=1)\n",
    "lw = 1\n",
    "plt.plot(fpr, tpr, lw=lw, label='ROC curve ')\n",
    "plt.plot([0, 1],[0, 1])\n",
    "plt.xlim([0.0, 1.])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.savefig(\"ROC.png\")\n",
    "plt.show()\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_index = np.argmax(tpr-fpr)\n",
    "roc_score = roc_auc_score(test_y.astype('int'), linear_pred_test_y[:,1])\n",
    "print('порог - '+ str(thresholds[max_index])) \n",
    "print('true positive rate(recall) - '+ str(tpr[max_index]))# \n",
    "print('false positive rate - '+ str(fpr[max_index]))\n",
    "print('roc score - ' +str(roc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TPR** тут конечно меньше, но и **FPR** меньше, так что тут нужно больше данных от заказчика о, том что хочется увидеть в итоге. Можно сказать, что логрегрессия относит к классу 1 большее число объектов чем GBM. В тоже время, площадь под кривой у GBM явно больше, поэтому он предпочтительнее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Кластеризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задача:**\n",
    "кластеризовать заданный набор данных (task2.csv). Предложить метрику и проверить качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "task2data = pd.read_csv('./task2_v3.csv', sep=';',header=0,index_col=False)\n",
    "task2data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "task2data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стандартизировать характеристики не нужно, так как нет какой-то доминирующей среди всех. Поэтому кстати можно спокойно использовать euclidian расстояние.  Можно начать с иерархического кластерного анализа.\n",
    "\n",
    "Расстояние между кластерами Ward и между объектами euclidean является стандартном де-факто. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "linkage = hierarchy.linkage(task2data, \n",
    "                            'ward', #расстояние между кластерами\n",
    "                            'euclidean' #расстояние между единичными объектами\n",
    "                           )\n",
    "linkage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dendrogram = hierarchy.dendrogram(linkage, orientation='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for dist in (10,15,30,60,120,190,260,400,500):\n",
    "    cluster_res = hierarchy.fcluster(linkage,dist, 'distance')\n",
    "    print('силуэт - ' + str(silhouette_score(task2data, cluster_res)) + ' количество кластеров - ' + str(cluster_res.max()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка силуэта говорит, что лучше остановиться в расстоянии между 60 и 120."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "task2data['hierarchy_cluster']= hierarchy.fcluster(linkage,120, 'distance')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "task2data.groupby('hierarchy_cluster').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hierarchy_cluster_result = task2data['hierarchy_cluster']\n",
    "task2data.groupby('hierarchy_cluster').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "colors={'1':'green', '4':'red', '2':'blue', '3':'black', '5':'orange','6':'yellow','7':'lime','8':'violet'}\n",
    "task2data['hierarchy_cluster'] = task2data['hierarchy_cluster'].astype(str)\n",
    "scatter_matrix(task2data,figsize=(26,26), diagonal='kde',alpha=0.6, c=task2data['hierarchy_cluster'].replace(colors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 кластеров вполне достаточно. Но перепроверим с помощью метода k-средних."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hierarchy_cluster_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "w = {}\n",
    "K = range(2,15)\n",
    "for kluster_size in K:\n",
    "    model = KMeans(n_clusters=kluster_size,random_state=42)\n",
    "    model.fit(task2data)\n",
    "    ss = silhouette_score(task2data, model.labels_)\n",
    "    w[str(kluster_size)] = {'w' : model.inertia_, 'silhouette' : ss}\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве критерий качества (простите за тавтологию), использован силуэт."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "w_plot=list(map((lambda x: x.get('w')), w.values()))\n",
    "plt.plot(K, w_plot,marker='o')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судя по графику и цифрам, переход с 7 до 8 кластеров довольно сильно влияет на W, в отличии от дальнейших переходов. \n",
    "Остановимся так же на 8ми кластерах. Да и оценка силуэта говорит о том же."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=8,random_state=42)\n",
    "model.fit(task2data)\n",
    "task2data['kmean_cluster'] = model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "task2data.groupby('kmean_cluster').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним силуэт иерархической кластеризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "silhouette_score(task2data, hierarchy_cluster_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем, что иерархическая кластеризация предпочтительнее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К сожалению, о характеристиках каждого кластера ничего бизнесово-полезного сказать не получится, кроме простых наблюдений. В 1ом кластере характеристики 2,3,4 принимают отрицательные значения, в 5ом -\n",
    "характеристики 1 и 2 положительны и т.д. \n",
    "\n",
    "p.s.\n",
    "Можно предположить, что это температуры в населённых пунктах по четырём сезонам года, тогда становится веселее :-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
